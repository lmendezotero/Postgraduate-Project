{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** Notebook Content **"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Introduction\n",
    "\n",
    "\n",
    "2. Data Preprocessing\n",
    "    - 2.1 Importing the required packages\n",
    "    - 2.2 Loading the dataset\n",
    "    - 2.3 Preparing the data\n",
    "        - 2.3.1 Remove variables with low correlation\n",
    "        - 2.3.2 Getting the Dependent and Independent variables\n",
    "        - 2.3.3 Creating new dataframes based on the data type\n",
    "\n",
    "\n",
    "3. Building a \"baseline\" model applying logistics regression\n",
    "    - 3.1 Build a prediction model with numerical variables\n",
    "    - 3.2 Build a prediction model with numerical and categorical variables \n",
    "        - 3.2.1 Apllying dummy variables\n",
    "        - 3.2.2 Convert the remaining categorical variables into numbers\n",
    "        - 3.2.3 Implement the same changes in the test set\n",
    "    - 3.3 Saving the changes\n",
    "         \n",
    "         \n",
    "4. Building a Random Forest Regressor\n",
    "    - 4.1 Defining the Random Forest Regressor baseline\n",
    "        - 4.1.1 Fitting the Random Forest Regressor\n",
    "        - 4.1.2 Predicting the results\n",
    "    - 4.2 Applying K-Fold Cross-Validation technique\n",
    "    - 4.3 Applying Grid-Search technique\n",
    "        - 4.3.1 Random Hyper-parameters Grid technique\n",
    "            - a) Creating a parameter grid\n",
    "            - b) Random Search Training\n",
    "            - c) Evaluate Random Search\n",
    "        - 4.3.2 Grid-Search technique\n",
    "            - a) Initiate the grid search model\n",
    "            - b) Fit the grid search to the data\n",
    "            - c) Fitting the final Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to create a predictive regression model applying logististcs regression and random forest regressor techniques."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Importing the requiered packages "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "      <th>SalePrice</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>208500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>2007</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>181500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>223500.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>70</td>\n",
       "      <td>RL</td>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>272</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2006</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "      <td>140000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2008</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "      <td>250000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 75 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
       "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
       "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
       "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
       "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
       "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
       "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
       "\n",
       "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
       "0        0       0       2    2008        WD         Normal  208500.0  \n",
       "1        0       0       5    2007        WD         Normal  181500.0  \n",
       "2        0       0       9    2008        WD         Normal  223500.0  \n",
       "3        0       0       2    2006        WD        Abnorml  140000.0  \n",
       "4        0       0      12    2008        WD         Normal  250000.0  \n",
       "\n",
       "[5 rows x 75 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the training set\n",
    "df_train_clean = pd.read_csv('df_train_clean.csv')\n",
    "df_train_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324, 75)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Preparing the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.1 Remove variables with low correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we have to remove those variables that have a low correlation compared to the dependent variable (SalePrice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove variables with low correlation\n",
    "df_train_clean.drop(['MoSold', 'ScreenPorch', '3SsnPorch', 'PoolArea', 'MiscVal', 'YrSold', 'LowQualFinSF', 'MSSubClass',\n",
    "               'BsmtFinSF2', 'BsmtHalfBath'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324, 65)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of the dataframe after removing the variables with low correlation\n",
    "df_train_clean.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.2 Getting the Dependent and Independent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the Dependent and Independent variables\n",
    "X_train = df_train_clean.iloc[:, :-1] #all lines, all columns except the last one\n",
    "y_train = df_train_clean.iloc[:, 64] #all lines, only the last column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1324, 64), (1324,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of X_train and y_train\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3.3 Creating new dataframes based on the data type "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start the creation of our prediction model builing some dataframes related to the datatype of the variables that are part of X_train. These dataframes will help us to build a pilot model composed of only numerical variables. \n",
    "\n",
    "Then, we are going to add categorical variables to our model to improve the score and the power prediction of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Create dtype dataframes\n",
    "#create a dataframe with only categorical variables\n",
    "df_object = X_train.select_dtypes(include=[object])\n",
    "#create a dataframe with only numerical variables\n",
    "df_number = X_train.select_dtypes(include=[np.number])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>...</th>\n",
       "      <th>Electrical</th>\n",
       "      <th>KitchenQual</th>\n",
       "      <th>Functional</th>\n",
       "      <th>GarageType</th>\n",
       "      <th>GarageFinish</th>\n",
       "      <th>GarageQual</th>\n",
       "      <th>GarageCond</th>\n",
       "      <th>PavedDrive</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Veenker</td>\n",
       "      <td>Feedr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>TA</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>CollgCr</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>Crawfor</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Detchd</td>\n",
       "      <td>Unf</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Abnorml</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RL</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>FR2</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>NoRidge</td>\n",
       "      <td>Norm</td>\n",
       "      <td>Norm</td>\n",
       "      <td>...</td>\n",
       "      <td>SBrkr</td>\n",
       "      <td>Gd</td>\n",
       "      <td>Typ</td>\n",
       "      <td>Attchd</td>\n",
       "      <td>RFn</td>\n",
       "      <td>TA</td>\n",
       "      <td>TA</td>\n",
       "      <td>Y</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  MSZoning Street LotShape LandContour Utilities LotConfig LandSlope  \\\n",
       "0       RL   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
       "1       RL   Pave      Reg         Lvl    AllPub       FR2       Gtl   \n",
       "2       RL   Pave      IR1         Lvl    AllPub    Inside       Gtl   \n",
       "3       RL   Pave      IR1         Lvl    AllPub    Corner       Gtl   \n",
       "4       RL   Pave      IR1         Lvl    AllPub       FR2       Gtl   \n",
       "\n",
       "  Neighborhood Condition1 Condition2  ... Electrical KitchenQual Functional  \\\n",
       "0      CollgCr       Norm       Norm  ...      SBrkr          Gd        Typ   \n",
       "1      Veenker      Feedr       Norm  ...      SBrkr          TA        Typ   \n",
       "2      CollgCr       Norm       Norm  ...      SBrkr          Gd        Typ   \n",
       "3      Crawfor       Norm       Norm  ...      SBrkr          Gd        Typ   \n",
       "4      NoRidge       Norm       Norm  ...      SBrkr          Gd        Typ   \n",
       "\n",
       "  GarageType GarageFinish GarageQual GarageCond PavedDrive SaleType  \\\n",
       "0     Attchd          RFn         TA         TA          Y       WD   \n",
       "1     Attchd          RFn         TA         TA          Y       WD   \n",
       "2     Attchd          RFn         TA         TA          Y       WD   \n",
       "3     Detchd          Unf         TA         TA          Y       WD   \n",
       "4     Attchd          RFn         TA         TA          Y       WD   \n",
       "\n",
       "  SaleCondition  \n",
       "0        Normal  \n",
       "1        Normal  \n",
       "2        Normal  \n",
       "3       Abnorml  \n",
       "4        Normal  \n",
       "\n",
       "[5 rows x 38 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_object.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSZoning', 'Street', 'LotShape', 'LandContour', 'Utilities',\n",
       "       'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n",
       "       'BldgType', 'HouseStyle', 'RoofStyle', 'RoofMatl', 'Exterior1st',\n",
       "       'Exterior2nd', 'MasVnrType', 'ExterQual', 'ExterCond', 'Foundation',\n",
       "       'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\n",
       "       'Heating', 'HeatingQC', 'CentralAir', 'Electrical', 'KitchenQual',\n",
       "       'Functional', 'GarageType', 'GarageFinish', 'GarageQual', 'GarageCond',\n",
       "       'PavedDrive', 'SaleType', 'SaleCondition'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_object.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments =>> We realized that we have a total of 38 numerical variables. For our predictive model, we have to convert them to numerics in order to be able to apply algorithms such as logistics regression and random forest. However, we can not transform them all at once, as in some cases it is convenient to turn some variables into dummy to achieve a positive impact on the total set of the model.\n",
    "\n",
    "In the following section, you will find more details about the categorical varaibles treatment. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>OverallCond</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>MasVnrArea</th>\n",
       "      <th>BsmtFinSF1</th>\n",
       "      <th>BsmtUnfSF</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>...</th>\n",
       "      <th>BedroomAbvGr</th>\n",
       "      <th>KitchenAbvGr</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>Fireplaces</th>\n",
       "      <th>GarageYrBlt</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "      <th>WoodDeckSF</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>65.0</td>\n",
       "      <td>8450</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>196.0</td>\n",
       "      <td>706.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>856.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>548.0</td>\n",
       "      <td>0</td>\n",
       "      <td>61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>80.0</td>\n",
       "      <td>9600</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.0</td>\n",
       "      <td>284.0</td>\n",
       "      <td>1262.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1976.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>460.0</td>\n",
       "      <td>298</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>68.0</td>\n",
       "      <td>11250</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>162.0</td>\n",
       "      <td>486.0</td>\n",
       "      <td>434.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>608.0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60.0</td>\n",
       "      <td>9550</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>0.0</td>\n",
       "      <td>216.0</td>\n",
       "      <td>540.0</td>\n",
       "      <td>756.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>642.0</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>272</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>84.0</td>\n",
       "      <td>14260</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>350.0</td>\n",
       "      <td>655.0</td>\n",
       "      <td>490.0</td>\n",
       "      <td>1145.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>836.0</td>\n",
       "      <td>192</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  YearRemodAdd  \\\n",
       "0         65.0     8450            7            5       2003          2003   \n",
       "1         80.0     9600            6            8       1976          1976   \n",
       "2         68.0    11250            7            5       2001          2002   \n",
       "3         60.0     9550            7            5       1915          1970   \n",
       "4         84.0    14260            8            5       2000          2000   \n",
       "\n",
       "   MasVnrArea  BsmtFinSF1  BsmtUnfSF  TotalBsmtSF  ...  BedroomAbvGr  \\\n",
       "0       196.0       706.0      150.0        856.0  ...             3   \n",
       "1         0.0       978.0      284.0       1262.0  ...             3   \n",
       "2       162.0       486.0      434.0        920.0  ...             3   \n",
       "3         0.0       216.0      540.0        756.0  ...             3   \n",
       "4       350.0       655.0      490.0       1145.0  ...             4   \n",
       "\n",
       "   KitchenAbvGr  TotRmsAbvGrd  Fireplaces  GarageYrBlt  GarageCars  \\\n",
       "0             1             8           0       2003.0         2.0   \n",
       "1             1             6           1       1976.0         2.0   \n",
       "2             1             6           1       2001.0         2.0   \n",
       "3             1             7           1       1998.0         3.0   \n",
       "4             1             9           1       2000.0         3.0   \n",
       "\n",
       "   GarageArea  WoodDeckSF  OpenPorchSF  EnclosedPorch  \n",
       "0       548.0           0           61              0  \n",
       "1       460.0         298            0              0  \n",
       "2       608.0           0           42              0  \n",
       "3       642.0           0           35            272  \n",
       "4       836.0         192           84              0  \n",
       "\n",
       "[5 rows x 26 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_number.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['LotFrontage', 'LotArea', 'OverallQual', 'OverallCond', 'YearBuilt',\n",
       "       'YearRemodAdd', 'MasVnrArea', 'BsmtFinSF1', 'BsmtUnfSF', 'TotalBsmtSF',\n",
       "       '1stFlrSF', '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'FullBath',\n",
       "       'HalfBath', 'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd',\n",
       "       'Fireplaces', 'GarageYrBlt', 'GarageCars', 'GarageArea', 'WoodDeckSF',\n",
       "       'OpenPorchSF', 'EnclosedPorch'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_number.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments => We realized that we have a total of 26 numerical variables. For our predictive model, we can we consider all the numerical variables, since both Logistics Regression and Random Forest operate with numerical variables and the volume is not very high. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Building a \"baseline\" model applying logistics regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Build a prediction model with numerical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.1 Pilot Model 1 (numerical variables with correlation > [+0.5 & -0.5] )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start creating a pilot model only with those variables that have a higher correlation with respect to the dependent variable (more than 0.50 of correlation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_model_1 = df_number[['OverallQual', 'GrLivArea', '1stFlrSF', 'FullBath', 'YearBuilt', 'YearRemodAdd',\n",
    "                           'TotRmsAbvGrd', 'GarageCars', 'GarageArea', 'TotalBsmtSF', 'GarageYrBlt']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324, 11)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilot_model_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting logistic Regression into the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_regressor_1 = LogisticRegression (random_state = 0)\n",
    "log_regressor_1.fit(pilot_model_1, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Important Note:__ The classifier learns the correlation between the df_number and the x_train. \n",
    "\n",
    "Now, let's start calculating the $R^2$ (coefficient of determination) regression score function, which determines the quality of the model to replicate the results and the proportion of variation of the results that can be explained by the model.\n",
    "\n",
    "**Best possible score is 1.0 and it can be negative** (because the model can be arbitrarily worse). A constant model that always predicts the expected value of y, disregarding the input features, would get a $R^2$ score of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.2190332326283988\n",
      "Training MSE: 1242486857.018127\n"
     ]
    }
   ],
   "source": [
    "#Compute Score (𝑅2) for the pilot_model_1 and y_training\n",
    "print('Training Score: {}'.format(log_regressor_1.score(pilot_model_1, y_train)))\n",
    "#Compute MSE (Mean Squared Error) for the pilot_model_1 and y_training\n",
    "print('Training MSE: {}'.format(np.mean((log_regressor_1.predict(pilot_model_1) - y_train)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Pilot Model 2 (all numerical variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to include all the numerical varaibles into the pilot model in order to check its performance and define a preliminary baseline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "pilot_model_2 = df_number[['OverallQual', 'GrLivArea', '1stFlrSF', 'FullBath', 'YearBuilt', 'YearRemodAdd',\n",
    "                           'TotRmsAbvGrd', 'GarageCars', 'GarageArea', 'TotalBsmtSF', 'GarageYrBlt', 'MasVnrArea' ,\n",
    "                           'BsmtFinSF1', 'LotFrontage', 'BsmtFullBath', 'Fireplaces', 'OpenPorchSF', 'WoodDeckSF', \n",
    "                           '2ndFlrSF', 'HalfBath','LotArea', 'BedroomAbvGr', 'OverallCond', 'KitchenAbvGr',\n",
    "                           'EnclosedPorch', 'BsmtUnfSF']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324, 26)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pilot_model_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting logistic Regression into the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_regressor_2 = LogisticRegression (random_state = 0)\n",
    "log_regressor_2.fit(pilot_model_2, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.6102719033232629\n",
      "Training MSE: 515970129.33912385\n"
     ]
    }
   ],
   "source": [
    "#Compute Score (𝑅2) for the pilot_model_2 and y_training\n",
    "print('Training Score: {}'.format(log_regressor_2.score(pilot_model_2, y_train)))\n",
    "#Compute MSE (Mean Squared Error) for the pilot_model_2 and y_training\n",
    "print('Training MSE: {}'.format(np.mean((log_regressor_2.predict(pilot_model_2) - y_train)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Comments:__ We realized that the Score and the MSE have improved after includding all numerical variables, which present a significant level of correlation with respect to the dependent variable.\n",
    "\n",
    "__Note [2]:__ We tried to improve the performance of the model checking the distribution of all the numerical variables that are part of the model to see what kind of distribution they showed and adjusting the distribution of those variables that followed a distribution close to the Gaussian by applying logarithms. \n",
    "\n",
    "However, we realized that the score of the Logistics Regression worsened after applying logaritm functions, so we decided  not to use this method to improve model performance, as the results are not as expected.\n",
    "\n",
    "You can check the details of our analysis clicking in the following link:\n",
    "\n",
    "[Notebook - Testing Variables Distribution Applying 'Logarithms'](https://github.com/lmendezotero/Postgraduate-Project/blob/master/House%20Prices%20Prediction/Testing%20Variables%20Distribution%20Applying%20'Logarithms'.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Build a prediction model with numerical and categorical variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.1  Convert some categorical variables into dummy variable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first step to build our predictive model keeping in mind both numerical and categorical variables is to convert into dummy those categorical variables that have a positive impact on the model and that have few options/classes in order to avoid a significantly increase the number of features in the dataset. \n",
    "\n",
    "We do not want to make this notebook too extensive and include the necessary code without falling into redundancies. So, we have already done this analysis in other notebooks, which are linked to this current file.\n",
    "\n",
    "In the following Jupyter Notebook you can see the analysis performed in which we converted into dummy variables all the variables that seemed to us subject to being converted and the impact of each variable on the performance of the model: \n",
    "\n",
    "[Categorical Data - Dummy Variables Testing](https://github.com/lmendezotero/Postgraduate-Project/blob/master/House%20Prices%20Prediction/Categorical%20Data%20-%20Dummy%20Variables%20Testing.ipynb)\n",
    "\n",
    "However, we found that certain variables ('ExterCond', 'Utilities' and 'Street') that were transformed to dummy did not provide a positive impact on the model. So, we have to exclude these variables from the dummy analysis and we created a final version of the Notebook, in which we have tested the performance of the model with all the choosen dummy variables and the remaining categorical variables converted into numbers.\n",
    "\n",
    "You can check the details of our analysis in the Jupyter Notebook:\n",
    "\n",
    "[Categorical Variables - Analysis & Testing.ipynb](https://github.com/lmendezotero/Postgraduate-Project/blob/master/House%20Prices%20Prediction/Categorical%20Data%20-%20Analysis%20%26%20Testing.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, let's go!\n",
    "\n",
    "We are going to start building our predictive model converting the choosen categorical variables into dummy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324, 99)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert the choosen categorical variables into dummy variables\n",
    "X_train = pd.get_dummies (X_train, columns = ['LotShape', 'LandContour', 'LandSlope', 'BldgType', 'MasVnrType', 'ExterQual', \n",
    "                                              'BsmtQual', 'BsmtCond', 'BsmtExposure', 'CentralAir', 'KitchenQual', \n",
    "                                              'GarageFinish', 'PavedDrive'])\n",
    "                                              \n",
    "#check the shape of df_object after converting the variables into dummy\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['MSZoning', 'LotFrontage', 'LotArea', 'Street', 'Utilities',\n",
       "       'LotConfig', 'Neighborhood', 'Condition1', 'Condition2', 'HouseStyle',\n",
       "       'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', 'RoofStyle',\n",
       "       'RoofMatl', 'Exterior1st', 'Exterior2nd', 'MasVnrArea', 'ExterCond',\n",
       "       'Foundation', 'BsmtFinType1', 'BsmtFinSF1', 'BsmtFinType2', 'BsmtUnfSF',\n",
       "       'TotalBsmtSF', 'Heating', 'HeatingQC', 'Electrical', '1stFlrSF',\n",
       "       '2ndFlrSF', 'GrLivArea', 'BsmtFullBath', 'FullBath', 'HalfBath',\n",
       "       'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Functional',\n",
       "       'Fireplaces', 'GarageType', 'GarageYrBlt', 'GarageCars', 'GarageArea',\n",
       "       'GarageQual', 'GarageCond', 'WoodDeckSF', 'OpenPorchSF',\n",
       "       'EnclosedPorch', 'SaleType', 'SaleCondition', 'LotShape_IR1',\n",
       "       'LotShape_IR2', 'LotShape_IR3', 'LotShape_Reg', 'LandContour_Bnk',\n",
       "       'LandContour_HLS', 'LandContour_Low', 'LandContour_Lvl',\n",
       "       'LandSlope_Gtl', 'LandSlope_Mod', 'LandSlope_Sev', 'BldgType_1Fam',\n",
       "       'BldgType_2fmCon', 'BldgType_Duplex', 'BldgType_Twnhs',\n",
       "       'BldgType_TwnhsE', 'MasVnrType_BrkCmn', 'MasVnrType_BrkFace',\n",
       "       'MasVnrType_None', 'MasVnrType_Stone', 'ExterQual_Ex', 'ExterQual_Fa',\n",
       "       'ExterQual_Gd', 'ExterQual_TA', 'BsmtQual_Ex', 'BsmtQual_Fa',\n",
       "       'BsmtQual_Gd', 'BsmtQual_TA', 'BsmtCond_Fa', 'BsmtCond_Gd',\n",
       "       'BsmtCond_Po', 'BsmtCond_TA', 'BsmtExposure_Av', 'BsmtExposure_Gd',\n",
       "       'BsmtExposure_Mn', 'BsmtExposure_No', 'CentralAir_N', 'CentralAir_Y',\n",
       "       'KitchenQual_Ex', 'KitchenQual_Fa', 'KitchenQual_Gd', 'KitchenQual_TA',\n",
       "       'GarageFinish_Fin', 'GarageFinish_RFn', 'GarageFinish_Unf',\n",
       "       'PavedDrive_N', 'PavedDrive_P', 'PavedDrive_Y'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the name of the columns after converting the variables into dummy\n",
    "X_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we proceed to merge all the dummy variables in the same pilot_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324, 74)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numerical model + dummy variables\n",
    "pilot_model_3 = X_train[['OverallQual', 'GrLivArea', '1stFlrSF', 'FullBath', 'YearBuilt', 'YearRemodAdd',\n",
    "                           'TotRmsAbvGrd', 'GarageCars', 'GarageArea', 'TotalBsmtSF', 'GarageYrBlt', 'MasVnrArea' ,\n",
    "                           'BsmtFinSF1', 'LotFrontage', 'BsmtFullBath', 'Fireplaces', 'OpenPorchSF', 'WoodDeckSF', \n",
    "                           '2ndFlrSF', 'HalfBath','LotArea', 'BedroomAbvGr', 'OverallCond', 'KitchenAbvGr',\n",
    "                           'EnclosedPorch', 'BsmtUnfSF', 'LandSlope_Gtl','LandSlope_Mod', 'LandSlope_Sev', 'LotShape_IR1', \n",
    "                           'LotShape_IR2', 'LotShape_IR3', 'LotShape_Reg', 'LandContour_Bnk', 'LandContour_HLS',\n",
    "                           'LandContour_Low', 'LandContour_Lvl', 'MasVnrType_BrkCmn', 'MasVnrType_BrkFace', 'MasVnrType_None', \n",
    "                           'MasVnrType_Stone', 'ExterQual_Ex', 'ExterQual_Fa', 'ExterQual_Gd', 'ExterQual_TA', 'BldgType_1Fam', \n",
    "                           'BldgType_2fmCon', 'BldgType_Duplex', 'BldgType_Twnhs', 'BldgType_TwnhsE', 'BsmtQual_Ex', \n",
    "                           'BsmtQual_Fa', 'BsmtQual_Gd', 'BsmtQual_TA', 'BsmtCond_Fa', 'BsmtCond_Gd', 'BsmtCond_Po', \n",
    "                           'BsmtCond_TA', 'BsmtExposure_Av', 'BsmtExposure_Gd', 'BsmtExposure_Mn', 'BsmtExposure_No', \n",
    "                           'CentralAir_N', 'CentralAir_Y', 'KitchenQual_Ex', 'KitchenQual_Fa', 'KitchenQual_Gd', \n",
    "                           'KitchenQual_TA', 'GarageFinish_Fin', 'GarageFinish_RFn', 'GarageFinish_Unf','PavedDrive_N', \n",
    "                           'PavedDrive_P', 'PavedDrive_Y']]\n",
    "\n",
    "pilot_model_3.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's fitting the X_training applying logistics regression to check the performance of the model after includding all the dummy variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting logistic Regression into the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_regressor_3 = LogisticRegression (random_state = 0)\n",
    "log_regressor_3.fit(pilot_model_3, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.7741691842900302\n",
      "Training MSE: 183925345.60725075\n"
     ]
    }
   ],
   "source": [
    "#Compute Score (𝑅2) for the pilot_model_3 and y_training\n",
    "print('Training Score: {}'.format(log_regressor_3.score(pilot_model_3, y_train)))\n",
    "#Compute MSE (Mean Squared Error) for the pilot_model_3 and y_training\n",
    "print('Training MSE: {}'.format(np.mean((log_regressor_3.predict(pilot_model_3) - y_train)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments =>> It looks like the Score and MSE of our model improved improved after apllying all the dummy variables compared to the pilot_model_2 (\"0.7741 VS 0.6102\" and \"183925345 VS 515970129\" respectively).\n",
    "\n",
    "So, the *combination of those dummy variables and the numerical variables have raised a positive impact on model performance*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.2 Convert the remaining categorical variables into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are going to convert the remaining categorical variables into numbers and check the performance of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the rest of the categorical variables into numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lencoders = {}\n",
    "\n",
    "for col in X_train.select_dtypes(include=['object']).columns:\n",
    "    lencoders[col] = LabelEncoder()\n",
    "    X_train[col] = lencoders[col].fit_transform(X_train[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1324 entries, 0 to 1323\n",
      "Data columns (total 99 columns):\n",
      "MSZoning              1324 non-null int32\n",
      "LotFrontage           1324 non-null float64\n",
      "LotArea               1324 non-null int64\n",
      "Street                1324 non-null int32\n",
      "Utilities             1324 non-null int32\n",
      "LotConfig             1324 non-null int32\n",
      "Neighborhood          1324 non-null int32\n",
      "Condition1            1324 non-null int32\n",
      "Condition2            1324 non-null int32\n",
      "HouseStyle            1324 non-null int32\n",
      "OverallQual           1324 non-null int64\n",
      "OverallCond           1324 non-null int64\n",
      "YearBuilt             1324 non-null int64\n",
      "YearRemodAdd          1324 non-null int64\n",
      "RoofStyle             1324 non-null int32\n",
      "RoofMatl              1324 non-null int32\n",
      "Exterior1st           1324 non-null int32\n",
      "Exterior2nd           1324 non-null int32\n",
      "MasVnrArea            1324 non-null float64\n",
      "ExterCond             1324 non-null int32\n",
      "Foundation            1324 non-null int32\n",
      "BsmtFinType1          1324 non-null int32\n",
      "BsmtFinSF1            1324 non-null float64\n",
      "BsmtFinType2          1324 non-null int32\n",
      "BsmtUnfSF             1324 non-null float64\n",
      "TotalBsmtSF           1324 non-null float64\n",
      "Heating               1324 non-null int32\n",
      "HeatingQC             1324 non-null int32\n",
      "Electrical            1324 non-null int32\n",
      "1stFlrSF              1324 non-null int64\n",
      "2ndFlrSF              1324 non-null int64\n",
      "GrLivArea             1324 non-null int64\n",
      "BsmtFullBath          1324 non-null float64\n",
      "FullBath              1324 non-null int64\n",
      "HalfBath              1324 non-null int64\n",
      "BedroomAbvGr          1324 non-null int64\n",
      "KitchenAbvGr          1324 non-null int64\n",
      "TotRmsAbvGrd          1324 non-null int64\n",
      "Functional            1324 non-null int32\n",
      "Fireplaces            1324 non-null int64\n",
      "GarageType            1324 non-null int32\n",
      "GarageYrBlt           1324 non-null float64\n",
      "GarageCars            1324 non-null float64\n",
      "GarageArea            1324 non-null float64\n",
      "GarageQual            1324 non-null int32\n",
      "GarageCond            1324 non-null int32\n",
      "WoodDeckSF            1324 non-null int64\n",
      "OpenPorchSF           1324 non-null int64\n",
      "EnclosedPorch         1324 non-null int64\n",
      "SaleType              1324 non-null int32\n",
      "SaleCondition         1324 non-null int32\n",
      "LotShape_IR1          1324 non-null uint8\n",
      "LotShape_IR2          1324 non-null uint8\n",
      "LotShape_IR3          1324 non-null uint8\n",
      "LotShape_Reg          1324 non-null uint8\n",
      "LandContour_Bnk       1324 non-null uint8\n",
      "LandContour_HLS       1324 non-null uint8\n",
      "LandContour_Low       1324 non-null uint8\n",
      "LandContour_Lvl       1324 non-null uint8\n",
      "LandSlope_Gtl         1324 non-null uint8\n",
      "LandSlope_Mod         1324 non-null uint8\n",
      "LandSlope_Sev         1324 non-null uint8\n",
      "BldgType_1Fam         1324 non-null uint8\n",
      "BldgType_2fmCon       1324 non-null uint8\n",
      "BldgType_Duplex       1324 non-null uint8\n",
      "BldgType_Twnhs        1324 non-null uint8\n",
      "BldgType_TwnhsE       1324 non-null uint8\n",
      "MasVnrType_BrkCmn     1324 non-null uint8\n",
      "MasVnrType_BrkFace    1324 non-null uint8\n",
      "MasVnrType_None       1324 non-null uint8\n",
      "MasVnrType_Stone      1324 non-null uint8\n",
      "ExterQual_Ex          1324 non-null uint8\n",
      "ExterQual_Fa          1324 non-null uint8\n",
      "ExterQual_Gd          1324 non-null uint8\n",
      "ExterQual_TA          1324 non-null uint8\n",
      "BsmtQual_Ex           1324 non-null uint8\n",
      "BsmtQual_Fa           1324 non-null uint8\n",
      "BsmtQual_Gd           1324 non-null uint8\n",
      "BsmtQual_TA           1324 non-null uint8\n",
      "BsmtCond_Fa           1324 non-null uint8\n",
      "BsmtCond_Gd           1324 non-null uint8\n",
      "BsmtCond_Po           1324 non-null uint8\n",
      "BsmtCond_TA           1324 non-null uint8\n",
      "BsmtExposure_Av       1324 non-null uint8\n",
      "BsmtExposure_Gd       1324 non-null uint8\n",
      "BsmtExposure_Mn       1324 non-null uint8\n",
      "BsmtExposure_No       1324 non-null uint8\n",
      "CentralAir_N          1324 non-null uint8\n",
      "CentralAir_Y          1324 non-null uint8\n",
      "KitchenQual_Ex        1324 non-null uint8\n",
      "KitchenQual_Fa        1324 non-null uint8\n",
      "KitchenQual_Gd        1324 non-null uint8\n",
      "KitchenQual_TA        1324 non-null uint8\n",
      "GarageFinish_Fin      1324 non-null uint8\n",
      "GarageFinish_RFn      1324 non-null uint8\n",
      "GarageFinish_Unf      1324 non-null uint8\n",
      "PavedDrive_N          1324 non-null uint8\n",
      "PavedDrive_P          1324 non-null uint8\n",
      "PavedDrive_Y          1324 non-null uint8\n",
      "dtypes: float64(9), int32(25), int64(17), uint8(48)\n",
      "memory usage: 460.4 KB\n"
     ]
    }
   ],
   "source": [
    "#check the datatype of X_train to review that all the variables are numbers\n",
    "X_train.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's merge all the variables in the same pilot_model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1324, 99)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#numerical model + all dummy variables + remaining numerical variables\n",
    "pilot_model_4 = X_train\n",
    "\n",
    "pilot_model_4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:432: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:469: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='warn', n_jobs=None, penalty='l2',\n",
       "                   random_state=0, solver='warn', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting logistic Regression into the Training set\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "log_regressor_4 = LogisticRegression (random_state = 0)\n",
    "log_regressor_4.fit(pilot_model_4, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.8919939577039275\n",
      "Training MSE: 57845974.32024169\n"
     ]
    }
   ],
   "source": [
    "#Compute Score (𝑅2) for the pilot_model_4 and y_training\n",
    "print('Training Score: {}'.format(log_regressor_4.score(pilot_model_4, y_train)))\n",
    "#Compute MSE (Mean Squared Error) for the pilot_model_4 and y_training\n",
    "print('Training MSE: {}'.format(np.mean((log_regressor_4.predict(pilot_model_4) - y_train)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we apply logistics regression with all the transformed variables, we observe that we achieve a Score of 0.89199 and a Mean Squared Error of result of 57.845.974, respectively.\n",
    "\n",
    "Therefore, consider the pilot_model_4 as the reference or baseline. So, the goal is to improve the Score and the MSE or our model applying one of the most famous ensemble algorithm that is called the Random Forest Regressor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.2.3 Implementing the changes in the test test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to build a good model and predict the results correctly, we have to implement in the test set the same changes we made earlier in the training set to have the inforamtion in the same format and get realistic results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Loading the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start loading the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSSubClass</th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>LotShape</th>\n",
       "      <th>LandContour</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>LandSlope</th>\n",
       "      <th>...</th>\n",
       "      <th>OpenPorchSF</th>\n",
       "      <th>EnclosedPorch</th>\n",
       "      <th>3SsnPorch</th>\n",
       "      <th>ScreenPorch</th>\n",
       "      <th>PoolArea</th>\n",
       "      <th>MiscVal</th>\n",
       "      <th>MoSold</th>\n",
       "      <th>YrSold</th>\n",
       "      <th>SaleType</th>\n",
       "      <th>SaleCondition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20</td>\n",
       "      <td>RH</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>Pave</td>\n",
       "      <td>Reg</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>RL</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Corner</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12500</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>60</td>\n",
       "      <td>RL</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>Lvl</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>120</td>\n",
       "      <td>RL</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>Pave</td>\n",
       "      <td>IR1</td>\n",
       "      <td>HLS</td>\n",
       "      <td>AllPub</td>\n",
       "      <td>Inside</td>\n",
       "      <td>Gtl</td>\n",
       "      <td>...</td>\n",
       "      <td>82</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>144</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2010</td>\n",
       "      <td>WD</td>\n",
       "      <td>Normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
       "0          20       RH         80.0    11622   Pave      Reg         Lvl   \n",
       "1          20       RL         81.0    14267   Pave      IR1         Lvl   \n",
       "2          60       RL         74.0    13830   Pave      IR1         Lvl   \n",
       "3          60       RL         78.0     9978   Pave      IR1         Lvl   \n",
       "4         120       RL         43.0     5005   Pave      IR1         HLS   \n",
       "\n",
       "  Utilities LotConfig LandSlope  ... OpenPorchSF EnclosedPorch 3SsnPorch  \\\n",
       "0    AllPub    Inside       Gtl  ...           0             0         0   \n",
       "1    AllPub    Corner       Gtl  ...          36             0         0   \n",
       "2    AllPub    Inside       Gtl  ...          34             0         0   \n",
       "3    AllPub    Inside       Gtl  ...          36             0         0   \n",
       "4    AllPub    Inside       Gtl  ...          82             0         0   \n",
       "\n",
       "  ScreenPorch PoolArea  MiscVal  MoSold  YrSold  SaleType SaleCondition  \n",
       "0         120        0        0       6    2010        WD        Normal  \n",
       "1           0        0    12500       6    2010        WD        Normal  \n",
       "2           0        0        0       3    2010        WD        Normal  \n",
       "3           0        0        0       6    2010        WD        Normal  \n",
       "4         144        0        0       1    2010        WD        Normal  \n",
       "\n",
       "[5 rows x 74 columns]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading the X_test dataset\n",
    "X_test = pd.read_csv('df_test_clean.csv')\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1319, 74)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of the test set\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Delete variables with low correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to remove those variables that show a low correlation with respect to the SalePrice variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "#remove variables with low correlation\n",
    "X_test.drop(['MoSold', 'ScreenPorch', '3SsnPorch', 'PoolArea', 'MiscVal', 'YrSold', 'LowQualFinSF', 'MSSubClass',\n",
    "               'BsmtFinSF2', 'BsmtHalfBath'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1319, 64)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the shape of the test set after removing variables with low correlation\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Convert some categorical variables into dummy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to convert into dummy variables some categorical features that have an impact on the SalePrice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1319, 99)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#convert some categorical variables into dummy variables\n",
    "X_test = pd.get_dummies (X_test, columns = ['LandSlope', 'LotShape', 'LandContour', 'MasVnrType', 'ExterQual', 'BldgType', \n",
    "                                             'BsmtQual', 'BsmtCond', 'BsmtExposure', 'CentralAir', 'KitchenQual', 'GarageFinish',\n",
    "                                             'PavedDrive'])\n",
    "\n",
    "#check the shape of test set after converting the variables into dummy\n",
    "X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### d) Convert the remaining categorical variables into numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regarding the remaining categorical variables, we have to convert them into numbers in order to buil our regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert the rest of the categorical variables into numbers\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "lencoders = {}\n",
    "\n",
    "for col in X_test.select_dtypes(include=['object']).columns:\n",
    "    lencoders[col] = LabelEncoder()\n",
    "    X_test[col] = lencoders[col].fit_transform(X_test[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1319 entries, 0 to 1318\n",
      "Data columns (total 99 columns):\n",
      "MSZoning              1319 non-null int32\n",
      "LotFrontage           1319 non-null float64\n",
      "LotArea               1319 non-null int64\n",
      "Street                1319 non-null int32\n",
      "Utilities             1319 non-null int32\n",
      "LotConfig             1319 non-null int32\n",
      "Neighborhood          1319 non-null int32\n",
      "Condition1            1319 non-null int32\n",
      "Condition2            1319 non-null int32\n",
      "HouseStyle            1319 non-null int32\n",
      "OverallQual           1319 non-null int64\n",
      "OverallCond           1319 non-null int64\n",
      "YearBuilt             1319 non-null int64\n",
      "YearRemodAdd          1319 non-null int64\n",
      "RoofStyle             1319 non-null int32\n",
      "RoofMatl              1319 non-null int32\n",
      "Exterior1st           1319 non-null int32\n",
      "Exterior2nd           1319 non-null int32\n",
      "MasVnrArea            1319 non-null float64\n",
      "ExterCond             1319 non-null int32\n",
      "Foundation            1319 non-null int32\n",
      "BsmtFinType1          1319 non-null int32\n",
      "BsmtFinSF1            1319 non-null float64\n",
      "BsmtFinType2          1319 non-null int32\n",
      "BsmtUnfSF             1319 non-null float64\n",
      "TotalBsmtSF           1319 non-null float64\n",
      "Heating               1319 non-null int32\n",
      "HeatingQC             1319 non-null int32\n",
      "Electrical            1319 non-null int32\n",
      "1stFlrSF              1319 non-null int64\n",
      "2ndFlrSF              1319 non-null int64\n",
      "GrLivArea             1319 non-null int64\n",
      "BsmtFullBath          1319 non-null float64\n",
      "FullBath              1319 non-null int64\n",
      "HalfBath              1319 non-null int64\n",
      "BedroomAbvGr          1319 non-null int64\n",
      "KitchenAbvGr          1319 non-null int64\n",
      "TotRmsAbvGrd          1319 non-null int64\n",
      "Functional            1319 non-null int32\n",
      "Fireplaces            1319 non-null int64\n",
      "GarageType            1319 non-null int32\n",
      "GarageYrBlt           1319 non-null float64\n",
      "GarageCars            1319 non-null float64\n",
      "GarageArea            1319 non-null float64\n",
      "GarageQual            1319 non-null int32\n",
      "GarageCond            1319 non-null int32\n",
      "WoodDeckSF            1319 non-null int64\n",
      "OpenPorchSF           1319 non-null int64\n",
      "EnclosedPorch         1319 non-null int64\n",
      "SaleType              1319 non-null int32\n",
      "SaleCondition         1319 non-null int32\n",
      "LandSlope_Gtl         1319 non-null uint8\n",
      "LandSlope_Mod         1319 non-null uint8\n",
      "LandSlope_Sev         1319 non-null uint8\n",
      "LotShape_IR1          1319 non-null uint8\n",
      "LotShape_IR2          1319 non-null uint8\n",
      "LotShape_IR3          1319 non-null uint8\n",
      "LotShape_Reg          1319 non-null uint8\n",
      "LandContour_Bnk       1319 non-null uint8\n",
      "LandContour_HLS       1319 non-null uint8\n",
      "LandContour_Low       1319 non-null uint8\n",
      "LandContour_Lvl       1319 non-null uint8\n",
      "MasVnrType_BrkCmn     1319 non-null uint8\n",
      "MasVnrType_BrkFace    1319 non-null uint8\n",
      "MasVnrType_None       1319 non-null uint8\n",
      "MasVnrType_Stone      1319 non-null uint8\n",
      "ExterQual_Ex          1319 non-null uint8\n",
      "ExterQual_Fa          1319 non-null uint8\n",
      "ExterQual_Gd          1319 non-null uint8\n",
      "ExterQual_TA          1319 non-null uint8\n",
      "BldgType_1Fam         1319 non-null uint8\n",
      "BldgType_2fmCon       1319 non-null uint8\n",
      "BldgType_Duplex       1319 non-null uint8\n",
      "BldgType_Twnhs        1319 non-null uint8\n",
      "BldgType_TwnhsE       1319 non-null uint8\n",
      "BsmtQual_Ex           1319 non-null uint8\n",
      "BsmtQual_Fa           1319 non-null uint8\n",
      "BsmtQual_Gd           1319 non-null uint8\n",
      "BsmtQual_TA           1319 non-null uint8\n",
      "BsmtCond_Fa           1319 non-null uint8\n",
      "BsmtCond_Gd           1319 non-null uint8\n",
      "BsmtCond_Po           1319 non-null uint8\n",
      "BsmtCond_TA           1319 non-null uint8\n",
      "BsmtExposure_Av       1319 non-null uint8\n",
      "BsmtExposure_Gd       1319 non-null uint8\n",
      "BsmtExposure_Mn       1319 non-null uint8\n",
      "BsmtExposure_No       1319 non-null uint8\n",
      "CentralAir_N          1319 non-null uint8\n",
      "CentralAir_Y          1319 non-null uint8\n",
      "KitchenQual_Ex        1319 non-null uint8\n",
      "KitchenQual_Fa        1319 non-null uint8\n",
      "KitchenQual_Gd        1319 non-null uint8\n",
      "KitchenQual_TA        1319 non-null uint8\n",
      "GarageFinish_Fin      1319 non-null uint8\n",
      "GarageFinish_RFn      1319 non-null uint8\n",
      "GarageFinish_Unf      1319 non-null uint8\n",
      "PavedDrive_N          1319 non-null uint8\n",
      "PavedDrive_P          1319 non-null uint8\n",
      "PavedDrive_Y          1319 non-null uint8\n",
      "dtypes: float64(9), int32(25), int64(17), uint8(48)\n",
      "memory usage: 458.6 KB\n"
     ]
    }
   ],
   "source": [
    "#check the datatype of X_train to review that all the variables are numbers\n",
    "X_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MSZoning</th>\n",
       "      <th>LotFrontage</th>\n",
       "      <th>LotArea</th>\n",
       "      <th>Street</th>\n",
       "      <th>Utilities</th>\n",
       "      <th>LotConfig</th>\n",
       "      <th>Neighborhood</th>\n",
       "      <th>Condition1</th>\n",
       "      <th>Condition2</th>\n",
       "      <th>HouseStyle</th>\n",
       "      <th>...</th>\n",
       "      <th>KitchenQual_Ex</th>\n",
       "      <th>KitchenQual_Fa</th>\n",
       "      <th>KitchenQual_Gd</th>\n",
       "      <th>KitchenQual_TA</th>\n",
       "      <th>GarageFinish_Fin</th>\n",
       "      <th>GarageFinish_RFn</th>\n",
       "      <th>GarageFinish_Unf</th>\n",
       "      <th>PavedDrive_N</th>\n",
       "      <th>PavedDrive_P</th>\n",
       "      <th>PavedDrive_Y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>80.0</td>\n",
       "      <td>11622</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>81.0</td>\n",
       "      <td>14267</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>74.0</td>\n",
       "      <td>13830</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>9978</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>43.0</td>\n",
       "      <td>5005</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   MSZoning  LotFrontage  LotArea  Street  Utilities  LotConfig  Neighborhood  \\\n",
       "0         2         80.0    11622       1          0          4            12   \n",
       "1         3         81.0    14267       1          0          0            12   \n",
       "2         3         74.0    13830       1          0          4             8   \n",
       "3         3         78.0     9978       1          0          4             8   \n",
       "4         3         43.0     5005       1          0          4            22   \n",
       "\n",
       "   Condition1  Condition2  HouseStyle  ...  KitchenQual_Ex  KitchenQual_Fa  \\\n",
       "0           1           2           2  ...               0               0   \n",
       "1           2           2           2  ...               0               0   \n",
       "2           2           2           4  ...               0               0   \n",
       "3           2           2           4  ...               0               0   \n",
       "4           2           2           2  ...               0               0   \n",
       "\n",
       "   KitchenQual_Gd  KitchenQual_TA  GarageFinish_Fin  GarageFinish_RFn  \\\n",
       "0               0               1                 0                 0   \n",
       "1               1               0                 0                 0   \n",
       "2               0               1                 1                 0   \n",
       "3               1               0                 1                 0   \n",
       "4               1               0                 0                 1   \n",
       "\n",
       "   GarageFinish_Unf  PavedDrive_N  PavedDrive_P  PavedDrive_Y  \n",
       "0                 1             0             0             1  \n",
       "1                 1             0             0             1  \n",
       "2                 0             0             0             1  \n",
       "3                 0             0             0             1  \n",
       "4                 0             0             0             1  \n",
       "\n",
       "[5 rows x 99 columns]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Review the final data\n",
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we are ready to training the Random Forest Regressor model, as the training set and test set are aligned."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Saving the changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: FutureWarning: The signature of `Series.to_csv` was aligned to that of `DataFrame.to_csv`, and argument 'header' will change its default value from False to True: please pass an explicit value to suppress this warning.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#export the baseline model to csv\n",
    "X_train.to_csv('Xtrain_baseline_model.csv', index=False)\n",
    "y_train.to_csv('ytrain_baseline_model.csv', index = False)\n",
    "X_test.to_csv('Xtest_baseline_model.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.to_pickle(\"./y_training.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Building a Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Defining the Random Forest Regressor baseline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start our analysis building a simple random forest regressor model, which is the baseline. Then, applying cross-validation techniques we will search what are the best parameters and we will apply them in order to build a solid and robust predictive model.  \n",
    "\n",
    "So, let's start creating the baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.1 Fitting the Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=10,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Random Forest Regression to the dataset\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf_regressor = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "rf_regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9739051625728526\n",
      "Training MSE: 123354012.79515868\n"
     ]
    }
   ],
   "source": [
    "#Compute Score (𝑅2) for the X_train and y_training\n",
    "print('Training Score: {}'.format(rf_regressor.score(X_train, y_train)))\n",
    "#Compute MSE (Mean Squared Error) for the X_train  and y_training\n",
    "print('Training MSE: {}'.format(np.mean((rf_regressor.predict(X_train) - y_train)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments =>> Comparing the results obtained in the random forest model compared to logistics regression, we verify that the random forest shows a greater potential, as we have increased the score by about 10% (from 0.895 to 0.974)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Predicting the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([126600., 154805., 178900., ...,  85250., 148860., 221970.])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set results\n",
    "y_pred = rf_regressor.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments => As we do not have any test labels (y_test) to validate the predictions of our model, we have to look for other method to corroborate that our model is trained properly (without falling into overfitting) and predicts new results correctly.\n",
    "\n",
    "One possible option could be applying **cross-validation techniques**, working and validating directly the data based on the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Applying K-Fold Cross-Validation technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most common cross-validation techniques is the**K-fold, which consists on splitting the training set into K number of subsets, called folds**. Then, we iteratively fit the model K times, each time training the data on K-1 of the folds and evaluating on the Kth fold (called the validation data). So, at the very end of training, we average the performance on each of the folds to come up with final validation metrics for the model.\n",
    "\n",
    "Let's see how the K-fold technique works with our random forest regressor model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score / Accuracy: 85.48 %\n",
      "Standard Deviation: 3.63 %\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(estimator = rf_regressor, X = X_train, y = y_train, cv = 10)\n",
    "print(\"Accuracy: {:.2f} %\".format(scores.mean()*100))\n",
    "print(\"Standard Deviation: {:.2f} %\".format(scores.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments: We got a maximum accuracy of 85.48% applying the K-fold cross-validation technique.\n",
    "\n",
    "Let's check how to improve the result with another popular cross-validation technique, which is called *Grid-Search tecnique*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Applying Grid-Search technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We would like to optimize our random forest model tunign some hyper-parameters to get a better performance. In order to do it, we will use the **\"Random Hyper-parameters Grid\" and \"Grid-Search\" method to find the best parameters for our regression model.**\n",
    "\n",
    "Before starting tunning the hyper-parameters, we need to check what are the parameters that we are using now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameters currently in use:\n",
      "\n",
      "{'bootstrap': True,\n",
      " 'criterion': 'mse',\n",
      " 'max_depth': None,\n",
      " 'max_features': 'auto',\n",
      " 'max_leaf_nodes': None,\n",
      " 'min_impurity_decrease': 0.0,\n",
      " 'min_impurity_split': None,\n",
      " 'min_samples_leaf': 1,\n",
      " 'min_samples_split': 2,\n",
      " 'min_weight_fraction_leaf': 0.0,\n",
      " 'n_estimators': 10,\n",
      " 'n_jobs': None,\n",
      " 'oob_score': False,\n",
      " 'random_state': 0,\n",
      " 'verbose': 0,\n",
      " 'warm_start': False}\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "# Look at parameters used by our current forest\n",
    "print('Parameters currently in use:\\n')\n",
    "pprint(rf_regressor_1.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will try adjusting the following set of hyperparameters:\n",
    "* __n_estimators__ = number of trees in the foreset\n",
    "* __max_features__ = max number of features considered for splitting a node\n",
    "* __max_depth__ = max number of levels in each decision tree\n",
    "* __min_samples_split__ = min number of data points placed in a node before the node is split\n",
    "* __min_samples_leaf__ = min number of data points allowed in a leaf node\n",
    "* __bootstrap__ = method for sampling data points (with or without replacement)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.1 Random Hyper-parameters Grid technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to start our analysis applying the **Random Hyper-parameters Grid technique**, whose benefit of a random search is that we are not trying every combination, but selecting at random to sample a wide range of values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Creating a parameter grid "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to apply the Random Hyper-parameters Grid technique, we have to use the **RandomizedSearchCV class**. So, we first need to create a parameter grid to sample from during fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bootstrap': [True, False],\n",
      " 'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 110, None],\n",
      " 'max_features': ['auto', 'sqrt'],\n",
      " 'min_samples_leaf': [1, 2, 4],\n",
      " 'min_samples_split': [2, 5, 10],\n",
      " 'n_estimators': [200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]}\n"
     ]
    }
   ],
   "source": [
    "## Creating a parameter grid\n",
    "\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['auto', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 10]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments =>> On each iteration, the algorithm will choose a difference combination of the features."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Random Search Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the random grid to search what are the most powerpul values of the hyper-parameters of the random forest regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 100 candidates, totalling 1000 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  33 tasks      | elapsed:   56.3s\n",
      "[Parallel(n_jobs=-1)]: Done 154 tasks      | elapsed: 10.8min\n",
      "[Parallel(n_jobs=-1)]: Done 357 tasks      | elapsed: 29.5min\n",
      "[Parallel(n_jobs=-1)]: Done 640 tasks      | elapsed: 47.6min\n",
      "[Parallel(n_jobs=-1)]: Done 1000 out of 1000 | elapsed: 74.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=10, error_score='raise-deprecating',\n",
       "                   estimator=RandomForestRegressor(bootstrap=True,\n",
       "                                                   criterion='mse',\n",
       "                                                   max_depth=None,\n",
       "                                                   max_features='auto',\n",
       "                                                   max_leaf_nodes=None,\n",
       "                                                   min_impurity_decrease=0.0,\n",
       "                                                   min_impurity_split=None,\n",
       "                                                   min_samples_leaf=1,\n",
       "                                                   min_samples_split=2,\n",
       "                                                   min_weight_fraction_leaf=0.0,\n",
       "                                                   n_estimators=10, n_jobs=None,\n",
       "                                                   oob_score=False,\n",
       "                                                   random_state=...\n",
       "                   iid='warn', n_iter=100, n_jobs=-1,\n",
       "                   param_distributions={'bootstrap': [True, False],\n",
       "                                        'max_depth': [10, 20, 30, 40, 50, 60,\n",
       "                                                      70, 80, 90, 100, 110,\n",
       "                                                      None],\n",
       "                                        'max_features': ['auto', 'sqrt'],\n",
       "                                        'min_samples_leaf': [1, 2, 4],\n",
       "                                        'min_samples_split': [2, 5, 10],\n",
       "                                        'n_estimators': [200, 400, 600, 800,\n",
       "                                                         1000, 1200, 1400, 1600,\n",
       "                                                         1800, 2000]},\n",
       "                   pre_dispatch='2*n_jobs', random_state=0, refit=True,\n",
       "                   return_train_score=False, scoring=None, verbose=2)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Use the random grid to search for best hyperparameters\n",
    "\n",
    "# First create the base model to tune\n",
    "rf_bm = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "\n",
    "# Random search of parameters, using 10 fold cross validation, \n",
    "# search across 100 different combinations, and use all available cores\n",
    "rf_random = RandomizedSearchCV(estimator = rf_bm, param_distributions = random_grid, n_iter = 100, cv =10, verbose=2, \n",
    "                               random_state=0, n_jobs = -1)\n",
    "\n",
    "# Fit the random search model\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments =>> The most important arguments in RandomizedSearchCV are n_iter, which controls the number of different combinations to try, and cv which is the number of folds to use for cross validation. In our case, we used a total of 100 iteractions and 10 folds. In addition, we realized that the run time has increased due to the number of folds chosen, but this allows us to reduce the risk of excess.\n",
    "\n",
    "\n",
    "Now, let's check the best parameters from fitting the random search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 1600,\n",
       " 'min_samples_split': 2,\n",
       " 'min_samples_leaf': 1,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 100,\n",
       " 'bootstrap': False}"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check the best random-search parameters\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#####  c) Evaluate Random Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To determine if random search got a better model, we compute the Score(R2) and MSE metrics of the rf_random model. Then, we compare the results of the random search model with the base model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9999955053205318\n",
      "Training MSE: 21246.989952617543\n"
     ]
    }
   ],
   "source": [
    "#Compute Score (𝑅2) for the rf_random and y_training\n",
    "print('Training Score: {}'.format(rf_random.score(X_train, y_train)))\n",
    "#Compute MSE (Mean Squared Error) for the rf_random  and y_training\n",
    "print('Training MSE: {}'.format(np.mean((rf_random.predict(X_train) - y_train)**2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explain and comment the results....."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can further improve our results by using grid search to focus on the most promising hyperparameters ranges found in the random search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3.2 Grid-Search technique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once we have are clear about the ranges of values that can fit our model to achieve a good score, we are ready to apply the grid-search technique to find the best parameters for our final predictive regression model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### a) Initiate the grid search model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Create the parameter grid based on the results of random search \n",
    "param_grid = [{\n",
    "    'bootstrap': [False],\n",
    "    'max_depth': [80, 90, 100, 110],\n",
    "    'max_features': [2, 3],\n",
    "    'min_samples_leaf': [1, 2, 3],\n",
    "    'min_samples_split': [1.0, 2, 3],\n",
    "    'n_estimators': [1000, 1200, 1400, 1600]}]\n",
    "\n",
    "# Create a based model\n",
    "rf_gs = RandomForestRegressor(n_estimators = 10, random_state = 0)\n",
    "\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf_gs, param_grid = param_grid, \n",
    "                          cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### b) Fit the grid search to the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Accuracy: 85.67 %\n",
      "Best Parameters: {'bootstrap': False, 'max_depth': 80, 'max_features': 3, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1400}\n"
     ]
    }
   ],
   "source": [
    "# Fit the grid search to the data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "#check the best grid-search accuracy\n",
    "best_accuracy = grid_search.best_score_\n",
    "#check the best grid-search parameters\n",
    "best_parameters = grid_search.best_params_\n",
    "print(\"Best Accuracy: {:.2f} %\".format(best_accuracy*100))\n",
    "print(\"Best Parameters:\", best_parameters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comments =>> Although the difference is not very large compared to the K-Fold cross-validation technique, we got a better accuracy result applying the Grid-search (85.67 instead of 85.48, respectively).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### c) Fitting the final Random Forest Regressor Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we proceed to build and fit the final Random Forest Regressor Model keeping in mind the best parameters values that the grid-search has provided us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=False, criterion='mse', max_depth=80,\n",
       "                      max_features=3, max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=1400,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Fitting the final Random Forest Regressor Model\n",
    "\n",
    "regressor_finalmodel = RandomForestRegressor(n_estimators = 1400, random_state = 0, bootstrap = False, max_depth = 80,\n",
    "                                             max_features = 3, min_samples_leaf = 1, min_samples_split = 2)\n",
    "\n",
    "regressor_finalmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: 0.9999954924677704\n",
      "Training MSE: 21307.74678617668\n"
     ]
    }
   ],
   "source": [
    "#Compute Score (𝑅2) for the regressor_finalmodel and y_training\n",
    "print('Training Score: {}'.format(regressor_finalmodel.score(X_train, y_train)))\n",
    "#Compute MSE (Mean Squared Error) for the regressor_finalmodel  and y_training\n",
    "print('Training MSE: {}'.format(np.mean((regressor_finalmodel.predict(X_train) - y_train)**2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([127374.48785714, 155743.18857143, 179954.93      , ...,\n",
       "        97405.93785714, 156186.78      , 221590.27285714])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predicting the test set results\n",
    "y_pred_finalmodel = regressor_finalmodel.predict(X_test)\n",
    "y_pred_finalmodel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__End of analysis.__\n",
    "\n",
    "__Thanks for reading!!__"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
